name: Learn then Analyze

on:
  workflow_dispatch:
    inputs:
      logLevel:
        description: 'Do not change'
        required: true
        default: 'dummy input'
      tags:
        description: 'dummy input, ignore'

jobs:
  learn:
    runs-on: self-hosted-ubuntu-with-docker
    timeout-minutes: 1440

    steps:
      - uses: actions/checkout@v2

      - name: Try to login to docker hub registry
        run: echo "${{ secrets.GITHUB_TOKEN }}" | docker login ghcr.io -u ${{ github.actor }} --password-stdin

      # Remember to update this hash whenever you update your Haskell dependencies in any way
      - name: Pull down image
        run: |
          time docker pull ghcr.io/learning-games/base:2021-11-01@sha256:c3b126b366be45f3ad92b2d73d3117a4170c0f77908c57327c2c15326ec6863d

      # Docker creates files as owner root (0). That means when the
      # runner, running as github, tries to delete the artifacts, it
      # fails. So we create a fresh copy of the current directory
      # under ~/run/$job_id and then remove that later with sudo. The
      # github user is a sudoer. That's not ideal, but the self-hosted
      # runner is private anyway.
      - name: Run learning process
        run: |
          # Setup working directory
          LEARN_FILENAME=$GITHUB_RUN_ID-learn.tar.gz
          ARCHIVE_LEARN=$(pwd)/$LEARN_FILENAME
          WORKDIR=~/run/$GITHUB_RUN_ID
          JOBDIR=$WORKDIR/results
          sudo mkdir -p $WORKDIR $JOBDIR
          sudo cp -r . $WORKDIR/

          # Run job
          time docker run -v$WORKDIR:$WORKDIR -w$WORKDIR --rm ghcr.io/learning-games/base:2021-11-01@sha256:c3b126b366be45f3ad92b2d73d3117a4170c0f77908c57327c2c15326ec6863d sh -c "stack build -j1 --fast --exec 'game local asymmetricLearners4Phases --skip-git'"

          # Archive output
          PW=$(pwd)
          cd $JOBDIR
          time tar czf $ARCHIVE_LEARN .
          cd $PW
          sudo rm -rf $JOBDIR

          # Upload output
          time s3cmd put $ARCHIVE_LEARN s3://pricing-game/

          # Wipe working directory
          sudo rm -rf $WORKDIR
  # analyze:
  #   needs: learn

  #   runs-on: self-hosted-ubuntu-with-docker

  #   steps:
  #     - uses: actions/checkout@v2

  #     - name: Try to login to docker hub registry
  #       run: echo "${{ secrets.GITHUB_TOKEN }}" | docker login ghcr.io -u ${{ github.actor }} --password-stdin

  #     # Remember to update this hash whenever you update your R dependencies in any way
  #     - name: Pull down image
  #       run: |
  #         time docker pull ghcr.io/learning-games/r:2021-11-11@sha256:08975d657fd2e84e611028460e55bd32484f34479785e7de4cb52b7d1be286e8

  #     # Docker creates files as owner root (0). That means when the
  #     # runner, running as github, tries to delete the artifacts, it
  #     # fails. So we create a fresh copy of the current directory
  #     # under ~/run/$job_id and then remove that later with sudo. The
  #     # github user is a sudoer. That's not ideal, but the self-hosted
  #     # runner is private anyway.
  #     - name: Run analysis process
  #       run: |
  #         # Setup working directory
  #         LEARN_FILENAME=$GITHUB_RUN_ID-learn.tar.gz
  #         ARCHIVE_LEARN=$(pwd)/$LEARN_FILENAME
  #         ARCHIVE_ANALYSIS=$(pwd)/$GITHUB_RUN_ID-analysis.tar.gz
  #         WORKDIR=~/run/$GITHUB_RUN_ID
  #         JOBDIR=$WORKDIR/job
  #         sudo mkdir -p $WORKDIR $JOBDIR
  #         sudo cp -r . $WORKDIR/

  #         # Download & unpack learning output
  #         time s3cmd get s3://pricing-game/$LEARN_FILENAME $ARCHIVE_LEARN
  #         tar xvf $ARCHIVE_LEARN

  #         # Run job
  #         time docker run -v$WORKDIR:$WORKDIR -w$WORKDIR --rm ghcr.io/learning-games/r:2021-11-11@sha256:08975d657fd2e84e611028460e55bd32484f34479785e7de4cb52b7d1be286e8 sh -c 'R --version'

          # # Archive output
          # PW=$(pwd)
          # cd $JOBDIR
          # time tar czf $ARCHIVE_ANALYSIS .
          # cd $PW
          # sudo rm -rf $JOBDIR

          # # Upload output
          # time s3cmd put $ARCHIVE_ANALYSIS s3://pricing-game/

          # # Wipe working directory
          # sudo rm -rf $WORKDIR
