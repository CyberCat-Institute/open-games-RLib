name: Analyze

on:
  workflow_dispatch:
    inputs:
      learn-run-id:
        description: 'The run ID for the Learn job'
        required: true
        default: ''

jobs:
  analyze:
    runs-on: self-hosted-ubuntu-with-docker

    steps:
      - uses: actions/checkout@v2

      - name: Try to login to docker hub registry
        run: echo "${{ secrets.GITHUB_TOKEN }}" | docker login ghcr.io -u ${{ github.actor }} --password-stdin

      # Remember to update this hash whenever you update your R dependencies in any way
      - name: Pull down image
        run: |
          time docker pull ghcr.io/learning-games/r:2021-11-11@sha256:08975d657fd2e84e611028460e55bd32484f34479785e7de4cb52b7d1be286e8

      # Docker creates files as owner root (0). That means when the
      # runner, running as github, tries to delete the artifacts, it
      # fails. So we create a fresh copy of the current directory
      # under ~/run/$job_id and then remove that later with sudo. The
      # github user is a sudoer. That's not ideal, but the self-hosted
      # runner is private anyway.
      - name: Run analysis process
        env:
          LEARN_RUNID: ${{ github.event.inputs.learn-run-id }}
        run: |
          # Grab experiment outputs
          LEARN_FILENAME=$LEARN_RUNID-learn.tar.gz
          ARCHIVE_LEARN=$(pwd)/$LEARN_FILENAME
          mkdir experiment

          # Download & unpack learning output
          mkdir extraction
          time s3cmd get s3://pricing-game/$LEARN_FILENAME $ARCHIVE_LEARN
          cd extraction
          tar xzf $ARCHIVE_LEARN
          cd ..
          mv extraction/*/* experiment/
          rm -r extraction
          # End of experiment extraction

          # Prepare outputs directory
          mkdir outputs

          # Check files
          ls -alh experiment/
          ls -alh Rscripts/




          # Setup working directory
          # ARCHIVE_ANALYSIS=$(pwd)/$GITHUB_RUN_ID-analysis.tar.gz
          # WORKDIR=~/run/$GITHUB_RUN_ID
          # JOBDIR=$WORKDIR/job
          # sudo mkdir -p $WORKDIR $JOBDIR
          # sudo cp -r . $WORKDIR/



          # Run job
          # docker run -v`pwd`/outputs:/outputs \
          #   -v$WORKDIR/Rscripts:/Rscripts \
          #   -v`pwd`/testGame-f1c54fe43a8e4f37b0f3f5891db4a235c71a1d99:/experiment/ \
          #   --rm \
          #   ghcr.io/learning-games/r:2021-11-11@sha256:08975d657fd2e84e611028460e55bd32484f34479785e7de4cb52b7d1be286e8 \
          #   R -f asymlearners_4phases.R

          # # Archive output
          # PW=$(pwd)
          # cd $JOBDIR
          # time tar czf $ARCHIVE_ANALYSIS .
          # cd $PW
          # sudo rm -rf $JOBDIR

          # # Upload output
          # time s3cmd put $ARCHIVE_ANALYSIS s3://pricing-game/

          # Wipe working directory
          sudo rm -rf $WORKDIR
