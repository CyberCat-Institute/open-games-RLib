name: Analyze

on:
  workflow_dispatch:
    inputs:
      learn-run-id:
        description: 'The run ID for the Learn job'
        required: true
        default: ''

jobs:
  analyze:
    runs-on: self-hosted-ubuntu-with-docker

    steps:
      - uses: actions/checkout@v2

      - name: Try to login to docker hub registry
        run: echo "${{ secrets.GITHUB_TOKEN }}" | docker login ghcr.io -u ${{ github.actor }} --password-stdin

      # Remember to update this hash whenever you update your R dependencies in any way
      - name: Pull down image
        run: |
          time docker pull ghcr.io/learning-games/r:2021-11-11@sha256:08975d657fd2e84e611028460e55bd32484f34479785e7de4cb52b7d1be286e8

      # Docker creates files as owner root (0). That means when the
      # runner, running as github, tries to delete the artifacts, it
      # fails. So we create a fresh copy of the current directory
      # under ~/run/$job_id and then remove that later with sudo. The
      # github user is a sudoer. That's not ideal, but the self-hosted
      # runner is private anyway.
      - name: Run analysis process
        env:
          LEARN_RUNID: ${{ github.event.inputs.learn-run-id }}
        run: |
          echo Workflow was run with input: learn-run-id=$LEARN_RUNID

          # Grab experiment outputs
          LEARN_FILENAME=$LEARN_RUNID-learn.tar.gz
          ARCHIVE_LEARN=$(pwd)/$LEARN_FILENAME

          # Setup directories
          mkdir experiment
          mkdir outputs

          # Download & unpack learning output
          mkdir extraction
          time s3cmd get s3://pricing-game/$LEARN_FILENAME $ARCHIVE_LEARN
          cd extraction
          tar xzf $ARCHIVE_LEARN
          cd ..
          mv extraction/*/* experiment/
          rm -r extraction
          # End of experiment extraction

          # Setup working directory
          ARCHIVE_ANALYSIS=$(pwd)/$GITHUB_RUN_ID-analysis.tar.gz
          WORKDIR=~/run/$GITHUB_RUN_ID
          sudo mkdir -p $WORKDIR $JOBDIR
          sudo cp -r . $WORKDIR/

          # Run job
          docker run \
            -v$WORKDIR/outputs:/outputs \
            -v$WORKDIR/Rscripts:/Rscripts \
            -v$WORKDIR/experiment:/experiment \
            --rm \
            ghcr.io/learning-games/r:2021-11-23@sha256:9a9b4071d863d3e541ee31162b3a869f9cfe9cd40ada6ee11425bc6fd2c46d21 \
            R -f /Rscripts/asymlearners_4phases.R

          echo Behold, the outputs are...
          ls -alh $WORKDIR/outputs

          # Archive output
          PW=$(pwd)
          cd $WORKDIR/outputs
          time tar czf $ARCHIVE_ANALYSIS .
          cd $PW

          # Upload output
          time s3cmd put $ARCHIVE_ANALYSIS s3://pricing-game/

          # Wipe working directory
          sudo rm -rf $WORKDIR
